{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FromTFtoPT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Yuy37OG0ggNeU_lx3HwyD2HEnUbc55n7",
      "authorship_tag": "ABX9TyPPqE1BJinLwDsBS7aLdp01"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52RX5Og6OX-p"
      },
      "source": [
        "#Assignment Set 4\n",
        "\n",
        "by **Amir Mehrpanah** for Deep Learing Course at Data Science Center, SBU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd3i2yUDGte1"
      },
      "source": [
        "##Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6rbm8tNM8SI"
      },
      "source": [
        "transformations = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize([.5],[.5])])\n",
        "\n",
        "# download data and apply transformations\n",
        "dataset = torchvision.datasets.FashionMNIST(root = 'data/',\n",
        "                                              download = True,train = True,\n",
        "                                              transform = transformations)\n",
        "\n",
        "# split data into two sets of 70/30 ratio\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [42000, 18000])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZRvs3DfdDQh"
      },
      "source": [
        "##Implementing The Fit Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTXwJFQpdNJl"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "def fit(model, train_data,loss_fn,optimizer,epochs,batch_size):\n",
        "    # use DataLoader\n",
        "    train_data_loader = DataLoader(train_data,batch_size=batch_size)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        true_pred = 0\n",
        "        for batch_idx, (train_imgs, train_labels) in enumerate(train_data_loader):\n",
        "            train_imgs = train_imgs.to(device)\n",
        "            train_labels = train_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            soft_y_pred = model(train_imgs)\n",
        "            loss = loss_fn(soft_y_pred, train_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            y_pred = torch.max(soft_y_pred.data, 1)[1] \n",
        "            true_pred += (y_pred == train_labels).sum()\n",
        "            \n",
        "            if batch_idx % 500 == 0:\n",
        "                print('Epoch : {} \\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(epoch,\n",
        "                                                                            loss.item(),\n",
        "                                                                            float(true_pred*100) / float(batch_size*(batch_idx+1))))\n",
        "\n",
        "def evaluate(model,batch_size,test_data):\n",
        "    test_data_loader = DataLoader(test_data,batch_size=batch_size)\n",
        "    true_pred = 0 \n",
        "    for test_imgs, test_labels in test_data_loader:\n",
        "        test_imgs = test_imgs.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "\n",
        "        soft_y_pred = model(test_imgs)\n",
        "        y_pred = torch.max(soft_y_pred,1)[1]\n",
        "        true_pred += (y_pred == test_labels).sum()\n",
        "    print(\"Test accuracy:{:.3f}% \".format(float(100*true_pred) / (len(test_data_loader)*batch_size)))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M4Mx87sGxWW"
      },
      "source": [
        "##NN.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wLARdehG7Xz",
        "outputId": "c4745484-7ed7-44b2-d923-adfcd028a855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "model = nn.Sequential(nn.Conv2d(1, 64,3),\n",
        "                      nn.ReLU(),\n",
        "\n",
        "                      nn.MaxPool2d(2),\n",
        "                      \n",
        "                      nn.Conv2d(64,64,3),\n",
        "                      nn.ReLU(),\n",
        "                      \n",
        "                      nn.Flatten(),\n",
        "                      nn.Sigmoid(),\n",
        "\n",
        "                      nn.Linear(7744,64),\n",
        "                      nn.ReLU(),\n",
        "                      \n",
        "                      nn.Linear(64,32),\n",
        "                      nn.ReLU6(),\n",
        "\n",
        "                      nn.Linear(32,10),                      \n",
        "                      nn.Softmax())\n",
        "\n",
        "model = model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "fit(model,\n",
        "    train_data=train_set,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    epochs=15,\n",
        "    batch_size=64)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 \tLoss: 2.303888\t Accuracy:6.250%\n",
            "Epoch : 0 \tLoss: 2.087528\t Accuracy:31.269%\n",
            "Epoch : 1 \tLoss: 1.971548\t Accuracy:60.938%\n",
            "Epoch : 1 \tLoss: 1.892798\t Accuracy:66.648%\n",
            "Epoch : 2 \tLoss: 1.807894\t Accuracy:70.312%\n",
            "Epoch : 2 \tLoss: 1.829028\t Accuracy:74.152%\n",
            "Epoch : 3 \tLoss: 1.767563\t Accuracy:71.875%\n",
            "Epoch : 3 \tLoss: 1.793944\t Accuracy:76.138%\n",
            "Epoch : 4 \tLoss: 1.746357\t Accuracy:75.000%\n",
            "Epoch : 4 \tLoss: 1.773741\t Accuracy:77.330%\n",
            "Epoch : 5 \tLoss: 1.731200\t Accuracy:75.000%\n",
            "Epoch : 5 \tLoss: 1.757480\t Accuracy:78.290%\n",
            "Epoch : 6 \tLoss: 1.722847\t Accuracy:75.000%\n",
            "Epoch : 6 \tLoss: 1.744038\t Accuracy:79.232%\n",
            "Epoch : 7 \tLoss: 1.718830\t Accuracy:75.000%\n",
            "Epoch : 7 \tLoss: 1.735199\t Accuracy:79.993%\n",
            "Epoch : 8 \tLoss: 1.717300\t Accuracy:75.000%\n",
            "Epoch : 8 \tLoss: 1.728971\t Accuracy:80.548%\n",
            "Epoch : 9 \tLoss: 1.715093\t Accuracy:75.000%\n",
            "Epoch : 9 \tLoss: 1.723411\t Accuracy:81.004%\n",
            "Epoch : 10 \tLoss: 1.713673\t Accuracy:75.000%\n",
            "Epoch : 10 \tLoss: 1.718517\t Accuracy:81.462%\n",
            "Epoch : 11 \tLoss: 1.710621\t Accuracy:75.000%\n",
            "Epoch : 11 \tLoss: 1.714900\t Accuracy:81.864%\n",
            "Epoch : 12 \tLoss: 1.707558\t Accuracy:76.562%\n",
            "Epoch : 12 \tLoss: 1.712950\t Accuracy:82.117%\n",
            "Epoch : 13 \tLoss: 1.704562\t Accuracy:78.125%\n",
            "Epoch : 13 \tLoss: 1.710721\t Accuracy:82.466%\n",
            "Epoch : 14 \tLoss: 1.701151\t Accuracy:78.125%\n",
            "Epoch : 14 \tLoss: 1.708785\t Accuracy:82.703%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjlSVeA4329P",
        "outputId": "7330611e-4f0d-4a8e-ff9a-a7f92677aa2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "evaluate(model,batch_size=64,test_data=test_set)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:81.998% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjNP7kYqG3am"
      },
      "source": [
        "##NN.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amSYMdLCQZUG"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5)    \n",
        "        self.lin1 = nn.Linear(in_features=64*3*3,out_features=100)    \n",
        "        self.lin2 = nn.Linear(in_features=100,out_features=64)    \n",
        "        self.lin3 = nn.Linear(in_features=64,out_features=32)    \n",
        "        self.lin4 = nn.Linear(in_features=32,out_features=10)  \n",
        "        \n",
        "    def forward(self,x): \n",
        "        # layer 1   \n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        # layer 2\n",
        "        x = torch.max_pool2d(x,kernel_size=3,stride=2)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        # layer 3\n",
        "        x = torch.max_pool2d(x,kernel_size=3,stride=2)\n",
        "        x = x.reshape(-1,64*3*3)\n",
        "        x = self.lin1(x)\n",
        "        x = torch.relu(x)\n",
        "        # layer 4\n",
        "        x = self.lin2(x)\n",
        "        x = torch.relu(x)    \n",
        "        # layer 5\n",
        "        x = self.lin3(x)\n",
        "        x = torch.relu(x)  \n",
        "        # layer 6\n",
        "        x = self.lin4(x)\n",
        "        x = F.softmax(x,dim=0)\n",
        "        return x\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J73iJpM3WTgk",
        "outputId": "31981a34-8e18-4c4e-c597-0fa0c61dc8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "model = Model()\n",
        "model = model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "fit(model,\n",
        "    train_data=train_set,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    epochs=15,\n",
        "    batch_size=64)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 \tLoss: 2.302584\t Accuracy:9.375%\n",
            "Epoch : 0 \tLoss: 2.209039\t Accuracy:48.356%\n",
            "Epoch : 1 \tLoss: 2.195250\t Accuracy:70.312%\n",
            "Epoch : 1 \tLoss: 2.191340\t Accuracy:64.970%\n",
            "Epoch : 2 \tLoss: 2.186258\t Accuracy:67.188%\n",
            "Epoch : 2 \tLoss: 2.191938\t Accuracy:67.241%\n",
            "Epoch : 3 \tLoss: 2.184922\t Accuracy:67.188%\n",
            "Epoch : 3 \tLoss: 2.192369\t Accuracy:68.865%\n",
            "Epoch : 4 \tLoss: 2.185551\t Accuracy:71.875%\n",
            "Epoch : 4 \tLoss: 2.190041\t Accuracy:69.985%\n",
            "Epoch : 5 \tLoss: 2.181469\t Accuracy:76.562%\n",
            "Epoch : 5 \tLoss: 2.187633\t Accuracy:70.924%\n",
            "Epoch : 6 \tLoss: 2.177785\t Accuracy:82.812%\n",
            "Epoch : 6 \tLoss: 2.186923\t Accuracy:71.912%\n",
            "Epoch : 7 \tLoss: 2.175957\t Accuracy:76.562%\n",
            "Epoch : 7 \tLoss: 2.184098\t Accuracy:72.811%\n",
            "Epoch : 8 \tLoss: 2.173222\t Accuracy:81.250%\n",
            "Epoch : 8 \tLoss: 2.183849\t Accuracy:73.843%\n",
            "Epoch : 9 \tLoss: 2.170268\t Accuracy:79.688%\n",
            "Epoch : 9 \tLoss: 2.184608\t Accuracy:74.301%\n",
            "Epoch : 10 \tLoss: 2.168926\t Accuracy:79.688%\n",
            "Epoch : 10 \tLoss: 2.184837\t Accuracy:74.582%\n",
            "Epoch : 11 \tLoss: 2.168279\t Accuracy:82.812%\n",
            "Epoch : 11 \tLoss: 2.184942\t Accuracy:74.959%\n",
            "Epoch : 12 \tLoss: 2.167922\t Accuracy:82.812%\n",
            "Epoch : 12 \tLoss: 2.184732\t Accuracy:75.259%\n",
            "Epoch : 13 \tLoss: 2.167661\t Accuracy:82.812%\n",
            "Epoch : 13 \tLoss: 2.184906\t Accuracy:75.499%\n",
            "Epoch : 14 \tLoss: 2.167377\t Accuracy:81.250%\n",
            "Epoch : 14 \tLoss: 2.184707\t Accuracy:75.755%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jASjHfJilKsc",
        "outputId": "6d9a0f03-0f1d-4fa6-9720-9ac282209942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluate(model,batch_size=64,test_data=test_set)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:74.632% \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}